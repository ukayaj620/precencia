{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Notebook\n",
    "\n",
    "This notebook is a tool to train the neural network for binary classification using the LFW Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thrid party libraries\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Import utility libraries\n",
    "\n",
    "from src.utils.triplet_generator import TripletGenerator\n",
    "\n",
    "# Import the core library from Precencia\n",
    "\n",
    "from src.core.face_encoder import FaceEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize utility libraries\n",
    "\n",
    "triplet_generator = TripletGenerator()\n",
    "\n",
    "# Initialize the classes\n",
    "\n",
    "face_encoder = FaceEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate triplets pairs to ease the setting up the data for training\n",
    "\n",
    "triplet_generator.lfw_dataset_source('\\data\\lfw')\n",
    "(anchors, positives, negatives) = triplet_generator.create_triplets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_generator.dataset_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction to get face embedding vectors, in (anchor, positive) and (anchor, negative) pair\n",
    "\n",
    "pair_embeddings = []\n",
    "y = []\n",
    "\n",
    "length = len(anchors)\n",
    "\n",
    "for idx in range(length):\n",
    "  anchor_embedding = face_encoder.get_embedding(image_path=anchors[idx])\n",
    "  positive_embedding = face_encoder.get_embedding(image_path=positives[idx])\n",
    "  negative_embedding = face_encoder.get_embedding(image_path=negatives[idx])\n",
    "\n",
    "  pair_embeddings.append((anchor_embedding, positive_embedding))\n",
    "  y.append(1)\n",
    "  pair_embeddings.append((anchor_embedding, negative_embedding))\n",
    "  y.append(0)\n",
    "\n",
    "\n",
    "np.save('./data/encodings/lfw_face_embeddings.npy', pair_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load face embedding pairs\n",
    "\n",
    "pair_embeddings = np.load('./data/encodings/lfw_face_embeddings.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "length = len(anchors)\n",
    "\n",
    "for _ in range(length):\n",
    "  y.append(1)\n",
    "  y.append(0)\n",
    "\n",
    "for embedding in pair_embeddings:\n",
    "  X.append(np.array(embedding[0] - embedding[1]).reshape(-1))\n",
    "\n",
    "X_train = np.array(X)\n",
    "y_train = np.array(y).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_scheduler(epoch, lr):\n",
    "  if (epoch % 5 == 0):\n",
    "    return lr * tf.math.exp(-0.1)\n",
    "  \n",
    "  return lr\n",
    "\n",
    "ClassifierLearningRateScheduler = LearningRateScheduler(classifier_scheduler, verbose=1)\n",
    "ClassifierCustomEarlyStopping = EarlyStopping(monitor='loss', patience=3)\n",
    "\n",
    "classifier = Sequential([\n",
    "            Input(shape=(128,)),\n",
    "            Dense(32, activation='relu'),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(loss='binary_crossentropy', optimizer=Adam(0.002), metrics=['accuracy'])\n",
    "classifier_training_history = classifier.fit(X_train, y_train, validation_split=0.2, callbacks=[\n",
    "               ClassifierLearningRateScheduler, ClassifierCustomEarlyStopping], epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classifier_training_history.history.keys())\n",
    "\n",
    "plt.plot(classifier_training_history.history['accuracy'])\n",
    "plt.plot(classifier_training_history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(classifier_training_history.history['loss'])\n",
    "plt.plot(classifier_training_history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(classifier_training_history.history['lr'])\n",
    "plt.title('Learning rate')\n",
    "plt.ylabel('learning rate')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['lr'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "classifier.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.save(\"./data/models/classifier_keras_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "774e75caea246c4358f04e0613681c0f16b060685ad186b54b70e43cb49089fd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Notebook\n",
    "\n",
    "This notebook is a tool to test the accuracy of the model using the validation dataset that has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import thrid party libraries\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Import the core library from Precencia\n",
    "\n",
    "from src.core.face_detector import FaceDetector\n",
    "from src.core.face_encoder import FaceEncoder\n",
    "from src.core.face_recognizer import FaceRecognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MTC Network] starting....\n",
      "[MTC Network] finish initialization....\n",
      "[Encoder Network] starting....\n",
      "[Inception ResNet V1] start to initialize...\n",
      "[Inception ResNet V1] finish initialize...\n",
      "[Encoder Network] finish initialization....\n",
      "[Inception ResNet V1] start loading weights...\n",
      "[Inception ResNet V1] finish loading weights...\n",
      "[Encoder Network] weights load successfully\n",
      "[Classifier Network] starting....\n",
      "[Classifier Network] start to initialize...\n",
      "[Classifier Network] finish initialize...\n",
      "[Classifier Network] finish initialization....\n",
      "[Classifier Network] start loading weights...\n",
      "[Classifier Network] finish loading weights...\n",
      "[Classifier Network] weights load successfully\n"
     ]
    }
   ],
   "source": [
    "face_detector = FaceDetector()\n",
    "face_encoder = FaceEncoder()\n",
    "face_recognizer = FaceRecognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amanda_Wulandari', 'Andreas_Dwi', 'Daniel', 'Daniel_Ronaldo', 'Derry_Leo_Nardi', 'Ellen_Pratama', 'Ferdy_Nicolas', 'Jason_Alexander', 'Jayaku_Briliantio', 'Kevin_Hosea']\n"
     ]
    }
   ],
   "source": [
    "names = os.listdir(os.getcwd() + '\\data\\\\validation')\n",
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n"
     ]
    }
   ],
   "source": [
    "# Create anchor embeddings\n",
    "\n",
    "anchor_embeddings = []\n",
    "\n",
    "for name in names:\n",
    "  path = os.getcwd() + '\\data\\\\validation\\\\{}\\\\{}_0001.jpg'.format(name, name)\n",
    "  extracted_face = face_detector.extract_face(image_path=path)\n",
    "  anchor_embeddings.append(face_encoder.get_embedding(image_array=extracted_face))\n",
    "\n",
    "np.save('./data/encodings/validation_anchor_embeddings.npy', anchor_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n",
      "Extraction in progress\n",
      "[MTCNN] Image loading done\n",
      "[MTCNN] Face is detected\n"
     ]
    }
   ],
   "source": [
    "# Create anchor embeddings\n",
    "\n",
    "input_embeddings = []\n",
    "\n",
    "for name in names:\n",
    "  images = os.listdir(os.getcwd() + '\\data\\\\validation\\\\{}'.format(name))\n",
    "  images.pop(0) # Pop the anchor image\n",
    "  input_person_embedding = []\n",
    "  for image in images:\n",
    "    path = os.getcwd() + '\\data\\\\validation\\\\{}\\\\{}'.format(name, image)\n",
    "    extracted_face = face_detector.extract_face(image_path=path)\n",
    "    input_person_embedding.append(face_encoder.get_embedding(image_array=extracted_face))\n",
    "  \n",
    "  input_embeddings.append(input_person_embedding)\n",
    "\n",
    "np.save('./data/encodings/validation_input_embeddings.npy', input_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128)\n",
      "(10, 5, 128)\n"
     ]
    }
   ],
   "source": [
    "# Load validation anchor and input embeddings\n",
    "\n",
    "anchor_embeddings = np.load('./data/encodings/validation_anchor_embeddings.npy')\n",
    "input_embeddings = np.load('./data/encodings/validation_input_embeddings.npy')\n",
    "\n",
    "print(np.shape(anchor_embeddings))\n",
    "print(np.shape(input_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_user(face_embedding):\n",
    "  similarities = [face_recognizer.compare(\n",
    "        face_embedding, anchor_embedding) for anchor_embedding in anchor_embeddings]\n",
    "  \n",
    "  max_similarity = max(similarities)\n",
    "  print(\"Maximum similarities: {}\".format(max_similarity))\n",
    "  max_similarity_index = similarities.index(max_similarity)\n",
    "\n",
    "  if max_similarity > 0.97:\n",
    "    user = names[max_similarity_index]\n",
    "    return user\n",
    "    \n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum similarities: 0.9999345541000366\n",
      "Actual User: Amanda_Wulandari, Predicted User: Amanda_Wulandari\n",
      "Maximum similarities: 0.9997243285179138\n",
      "Actual User: Amanda_Wulandari, Predicted User: Amanda_Wulandari\n",
      "Maximum similarities: 0.999789297580719\n",
      "Actual User: Amanda_Wulandari, Predicted User: Amanda_Wulandari\n",
      "Maximum similarities: 0.999009370803833\n",
      "Actual User: Amanda_Wulandari, Predicted User: Amanda_Wulandari\n",
      "Maximum similarities: 0.9993632435798645\n",
      "Actual User: Amanda_Wulandari, Predicted User: Amanda_Wulandari\n",
      "\n",
      "\n",
      "Maximum similarities: 0.9950913190841675\n",
      "Actual User: Andreas_Dwi, Predicted User: Andreas_Dwi\n",
      "Maximum similarities: 0.999154806137085\n",
      "Actual User: Andreas_Dwi, Predicted User: Andreas_Dwi\n",
      "Maximum similarities: 0.9993701577186584\n",
      "Actual User: Andreas_Dwi, Predicted User: Andreas_Dwi\n",
      "Maximum similarities: 0.9997842907905579\n",
      "Actual User: Andreas_Dwi, Predicted User: Andreas_Dwi\n",
      "Maximum similarities: 0.9998681545257568\n",
      "Actual User: Andreas_Dwi, Predicted User: Andreas_Dwi\n",
      "\n",
      "\n",
      "Maximum similarities: 0.9950217008590698\n",
      "Actual User: Daniel, Predicted User: Ferdy_Nicolas\n",
      "Maximum similarities: 0.990006685256958\n",
      "Actual User: Daniel, Predicted User: Ferdy_Nicolas\n",
      "Maximum similarities: 0.987973690032959\n",
      "Actual User: Daniel, Predicted User: Ferdy_Nicolas\n",
      "Maximum similarities: 0.9875770807266235\n",
      "Actual User: Daniel, Predicted User: Daniel\n",
      "Maximum similarities: 0.9900193214416504\n",
      "Actual User: Daniel, Predicted User: Daniel\n",
      "\n",
      "\n",
      "Maximum similarities: 0.9998956918716431\n",
      "Actual User: Daniel_Ronaldo, Predicted User: Daniel_Ronaldo\n",
      "Maximum similarities: 0.9999072551727295\n",
      "Actual User: Daniel_Ronaldo, Predicted User: Daniel_Ronaldo\n",
      "Maximum similarities: 0.9997840523719788\n",
      "Actual User: Daniel_Ronaldo, Predicted User: Daniel_Ronaldo\n",
      "Maximum similarities: 0.9996371269226074\n",
      "Actual User: Daniel_Ronaldo, Predicted User: Daniel_Ronaldo\n",
      "Maximum similarities: 0.9810718894004822\n",
      "Actual User: Daniel_Ronaldo, Predicted User: Daniel_Ronaldo\n",
      "\n",
      "\n",
      "Maximum similarities: 0.9993927478790283\n",
      "Actual User: Derry_Leo_Nardi, Predicted User: Derry_Leo_Nardi\n",
      "Maximum similarities: 0.9997835755348206\n",
      "Actual User: Derry_Leo_Nardi, Predicted User: Derry_Leo_Nardi\n",
      "Maximum similarities: 0.9995837807655334\n",
      "Actual User: Derry_Leo_Nardi, Predicted User: Derry_Leo_Nardi\n",
      "Maximum similarities: 0.9998558759689331\n",
      "Actual User: Derry_Leo_Nardi, Predicted User: Derry_Leo_Nardi\n",
      "Maximum similarities: 0.9998340606689453\n",
      "Actual User: Derry_Leo_Nardi, Predicted User: Derry_Leo_Nardi\n",
      "\n",
      "\n",
      "Maximum similarities: 0.9997797608375549\n",
      "Actual User: Ellen_Pratama, Predicted User: Ellen_Pratama\n",
      "Maximum similarities: 0.9914911389350891\n",
      "Actual User: Ellen_Pratama, Predicted User: Ellen_Pratama\n",
      "Maximum similarities: 0.9792786836624146\n",
      "Actual User: Ellen_Pratama, Predicted User: Ellen_Pratama\n",
      "Maximum similarities: 0.9999369382858276\n",
      "Actual User: Ellen_Pratama, Predicted User: Ellen_Pratama\n",
      "Maximum similarities: 0.9873718023300171\n",
      "Actual User: Ellen_Pratama, Predicted User: Amanda_Wulandari\n",
      "\n",
      "\n",
      "Maximum similarities: 0.9998582601547241\n",
      "Actual User: Ferdy_Nicolas, Predicted User: Ferdy_Nicolas\n",
      "Maximum similarities: 0.9999440908432007\n",
      "Actual User: Ferdy_Nicolas, Predicted User: Ferdy_Nicolas\n",
      "Maximum similarities: 0.9998887777328491\n",
      "Actual User: Ferdy_Nicolas, Predicted User: Ferdy_Nicolas\n",
      "Maximum similarities: 0.9997665286064148\n",
      "Actual User: Ferdy_Nicolas, Predicted User: Ferdy_Nicolas\n",
      "Maximum similarities: 0.9997981190681458\n",
      "Actual User: Ferdy_Nicolas, Predicted User: Ferdy_Nicolas\n",
      "\n",
      "\n",
      "Maximum similarities: 0.9997864365577698\n",
      "Actual User: Jason_Alexander, Predicted User: Jason_Alexander\n",
      "Maximum similarities: 0.9998078942298889\n",
      "Actual User: Jason_Alexander, Predicted User: Jason_Alexander\n",
      "Maximum similarities: 0.9995655417442322\n",
      "Actual User: Jason_Alexander, Predicted User: Jason_Alexander\n",
      "Maximum similarities: 0.9998592138290405\n",
      "Actual User: Jason_Alexander, Predicted User: Jason_Alexander\n",
      "Maximum similarities: 0.9998630285263062\n",
      "Actual User: Jason_Alexander, Predicted User: Jason_Alexander\n",
      "\n",
      "\n",
      "Maximum similarities: 0.9997331500053406\n",
      "Actual User: Jayaku_Briliantio, Predicted User: Jayaku_Briliantio\n",
      "Maximum similarities: 0.9898253083229065\n",
      "Actual User: Jayaku_Briliantio, Predicted User: Jayaku_Briliantio\n",
      "Maximum similarities: 0.996208906173706\n",
      "Actual User: Jayaku_Briliantio, Predicted User: Jayaku_Briliantio\n",
      "Maximum similarities: 0.999936580657959\n",
      "Actual User: Jayaku_Briliantio, Predicted User: Jayaku_Briliantio\n",
      "Maximum similarities: 0.9999178647994995\n",
      "Actual User: Jayaku_Briliantio, Predicted User: Jayaku_Briliantio\n",
      "\n",
      "\n",
      "Maximum similarities: 0.9993947744369507\n",
      "Actual User: Kevin_Hosea, Predicted User: Kevin_Hosea\n",
      "Maximum similarities: 0.9980711340904236\n",
      "Actual User: Kevin_Hosea, Predicted User: Kevin_Hosea\n",
      "Maximum similarities: 0.9985974431037903\n",
      "Actual User: Kevin_Hosea, Predicted User: Kevin_Hosea\n",
      "Maximum similarities: 0.9986699819564819\n",
      "Actual User: Kevin_Hosea, Predicted User: Kevin_Hosea\n",
      "Maximum similarities: 0.9994038343429565\n",
      "Actual User: Kevin_Hosea, Predicted User: Kevin_Hosea\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "true_predicted = []\n",
    "false_predicted = []\n",
    "not_predicted = []\n",
    "\n",
    "for idx, input_person_embedding in enumerate(input_embeddings):\n",
    "  current_user = names[idx]\n",
    "  true_predicted_user = 0\n",
    "  false_predicted_user = 0\n",
    "  not_predicted_user = 0\n",
    "  for face_embedding in input_person_embedding:\n",
    "    user = predict_user(face_embedding)\n",
    "    if user is not None:\n",
    "      print(\"Actual User: {}, Predicted User: {}\".format(current_user, user))\n",
    "      if user == current_user:\n",
    "        true_predicted_user += 1\n",
    "      else:\n",
    "        false_predicted_user += 1\n",
    "    else:\n",
    "      not_predicted_user += 1\n",
    "  \n",
    "  true_predicted.append(true_predicted_user)\n",
    "  false_predicted.append(false_predicted_user)\n",
    "  not_predicted.append(not_predicted_user)\n",
    "  print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 2, 5, 5, 4, 5, 5, 5, 5]\n",
      "[0, 0, 3, 0, 0, 1, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "True Predicted: 0.92\n",
      "False Predicted: 0.08\n"
     ]
    }
   ],
   "source": [
    "print(true_predicted)\n",
    "print(false_predicted)\n",
    "print(not_predicted)\n",
    "\n",
    "true_predicted_percentage = np.sum(true_predicted) / (len(names) * 5)\n",
    "false_predicted_accuracy = np.sum(false_predicted) / (len(names) * 5)\n",
    "\n",
    "print(\"True Predicted: {}\".format(true_predicted_percentage))\n",
    "print(\"False Predicted: {}\".format(false_predicted_accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "774e75caea246c4358f04e0613681c0f16b060685ad186b54b70e43cb49089fd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
